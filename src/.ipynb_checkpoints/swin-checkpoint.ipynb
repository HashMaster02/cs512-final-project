{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873bc42c",
   "metadata": {},
   "source": [
    "# Swin Transformer vs. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbeea447",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/0d/4a/e51420d46cfc90562e85af2fee912237c662ab31140ab179e49bd69401d6/torch-2.5.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torch-2.5.1-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Obtaining dependency information for typing-extensions>=4.8.0 from https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Obtaining dependency information for sympy==1.13.1 from https://files.pythonhosted.org/packages/b2/fe/81695a1aa331a842b582453b605175f419fe8540355886031328089d840a/sympy-1.13.1-py3-none-any.whl.metadata\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Downloading torch-2.5.1-cp311-cp311-win_amd64.whl (203.1 MB)\n",
      "   ---------------------------------------- 0.0/203.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/203.1 MB 11.6 MB/s eta 0:00:18\n",
      "   ---------------------------------------- 0.7/203.1 MB 10.6 MB/s eta 0:00:20\n",
      "   ---------------------------------------- 1.4/203.1 MB 12.9 MB/s eta 0:00:16\n",
      "   ---------------------------------------- 2.0/203.1 MB 13.0 MB/s eta 0:00:16\n",
      "    --------------------------------------- 2.8/203.1 MB 14.0 MB/s eta 0:00:15\n",
      "    --------------------------------------- 3.0/203.1 MB 12.1 MB/s eta 0:00:17\n",
      "    --------------------------------------- 3.5/203.1 MB 11.7 MB/s eta 0:00:18\n",
      "    --------------------------------------- 3.9/203.1 MB 11.2 MB/s eta 0:00:18\n",
      "    --------------------------------------- 4.3/203.1 MB 10.9 MB/s eta 0:00:19\n",
      "    --------------------------------------- 4.7/203.1 MB 10.7 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 5.2/203.1 MB 10.7 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 5.6/203.1 MB 10.5 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 6.1/203.1 MB 10.5 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 6.7/203.1 MB 10.7 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 7.2/203.1 MB 10.8 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 7.9/203.1 MB 11.0 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 8.5/203.1 MB 11.1 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 9.0/203.1 MB 11.1 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 9.6/203.1 MB 11.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 10.3/203.1 MB 11.3 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 10.9/203.1 MB 11.5 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 11.4/203.1 MB 11.3 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 12.0/203.1 MB 11.3 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 12.6/203.1 MB 11.3 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 13.1/203.1 MB 11.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 13.8/203.1 MB 11.7 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 14.4/203.1 MB 12.1 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 15.0/203.1 MB 12.1 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 15.7/203.1 MB 12.6 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 16.3/203.1 MB 12.8 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 17.0/203.1 MB 12.8 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 17.6/203.1 MB 12.8 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 18.1/203.1 MB 12.8 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 18.7/203.1 MB 12.6 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 19.3/203.1 MB 12.8 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 20.0/203.1 MB 12.9 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 20.6/203.1 MB 12.8 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 21.3/203.1 MB 13.1 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 21.9/203.1 MB 13.1 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 22.5/203.1 MB 13.1 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 23.2/203.1 MB 13.1 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 23.8/203.1 MB 13.4 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 24.5/203.1 MB 13.4 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 24.9/203.1 MB 12.9 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 25.5/203.1 MB 13.1 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 26.0/203.1 MB 13.1 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 26.6/203.1 MB 13.1 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 27.2/203.1 MB 12.8 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 27.8/203.1 MB 12.8 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 28.4/203.1 MB 13.1 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 28.9/203.1 MB 13.1 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 29.5/203.1 MB 12.9 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 30.0/203.1 MB 12.6 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 30.6/203.1 MB 12.6 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 31.3/203.1 MB 12.9 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 31.9/203.1 MB 12.6 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 32.5/203.1 MB 12.6 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 33.0/203.1 MB 12.6 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 33.6/203.1 MB 12.6 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 34.1/203.1 MB 12.1 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 34.7/203.1 MB 12.4 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 35.3/203.1 MB 12.1 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 35.8/203.1 MB 12.1 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 36.5/203.1 MB 12.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 37.0/203.1 MB 12.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 37.7/203.1 MB 12.4 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 38.5/203.1 MB 12.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 39.2/203.1 MB 12.8 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 39.9/203.1 MB 13.1 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 40.6/203.1 MB 13.4 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 41.3/203.1 MB 13.6 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 41.9/203.1 MB 13.4 MB/s eta 0:00:13\n",
      "   -------- ------------------------------- 42.7/203.1 MB 13.6 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 43.4/203.1 MB 14.2 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 44.2/203.1 MB 14.6 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 45.0/203.1 MB 14.9 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 45.8/203.1 MB 15.2 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 46.5/203.1 MB 15.2 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 47.2/203.1 MB 15.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 47.8/203.1 MB 15.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 48.5/203.1 MB 15.2 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 49.2/203.1 MB 15.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 49.8/203.1 MB 15.6 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 50.5/203.1 MB 15.2 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 51.0/203.1 MB 14.9 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 51.6/203.1 MB 14.9 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 52.4/203.1 MB 14.9 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 53.0/203.1 MB 14.9 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 53.7/203.1 MB 14.6 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 54.4/203.1 MB 14.6 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 55.0/203.1 MB 14.6 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 55.8/203.1 MB 14.6 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 56.5/203.1 MB 14.2 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 57.2/203.1 MB 14.2 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 57.8/203.1 MB 14.2 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 58.6/203.1 MB 14.6 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 59.2/203.1 MB 14.6 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 59.8/203.1 MB 14.2 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 60.5/203.1 MB 14.2 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 60.9/203.1 MB 14.2 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 61.6/203.1 MB 14.2 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 62.1/203.1 MB 13.9 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 62.8/203.1 MB 13.9 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 63.5/203.1 MB 13.9 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 64.2/203.1 MB 14.2 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 65.0/203.1 MB 14.2 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 65.6/203.1 MB 14.2 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 66.3/203.1 MB 13.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 66.9/203.1 MB 13.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 67.6/203.1 MB 13.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 68.3/203.1 MB 13.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 69.0/203.1 MB 13.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 69.6/203.1 MB 13.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 70.2/203.1 MB 13.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 70.8/203.1 MB 13.9 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 71.4/203.1 MB 13.9 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 72.1/203.1 MB 14.2 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 72.8/203.1 MB 14.2 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 73.5/203.1 MB 14.2 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 74.1/203.1 MB 14.2 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 74.9/203.1 MB 14.2 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 75.7/203.1 MB 14.2 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 76.4/203.1 MB 14.2 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 77.0/203.1 MB 14.6 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 77.7/203.1 MB 14.2 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 78.3/203.1 MB 14.2 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 78.9/203.1 MB 14.2 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 79.6/203.1 MB 14.6 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 80.3/203.1 MB 14.2 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 81.1/203.1 MB 14.6 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 81.7/203.1 MB 14.6 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 82.3/203.1 MB 14.6 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 83.1/203.1 MB 14.6 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 83.8/203.1 MB 14.9 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 84.5/203.1 MB 14.6 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 85.3/203.1 MB 14.6 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 85.9/203.1 MB 14.6 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 86.7/203.1 MB 14.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 87.3/203.1 MB 14.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 87.9/203.1 MB 14.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 88.6/203.1 MB 14.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 89.3/203.1 MB 14.9 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 90.0/203.1 MB 14.9 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 90.7/203.1 MB 14.9 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 91.3/203.1 MB 14.9 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 91.8/203.1 MB 14.6 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 92.5/203.1 MB 14.6 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 93.0/203.1 MB 14.6 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 93.7/203.1 MB 14.2 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 94.4/203.1 MB 13.9 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 94.9/203.1 MB 14.2 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 95.3/203.1 MB 13.4 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 95.8/203.1 MB 13.4 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 96.5/203.1 MB 13.4 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 97.0/203.1 MB 13.4 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 97.7/203.1 MB 13.4 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 98.3/203.1 MB 13.1 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 98.9/203.1 MB 13.1 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 99.5/203.1 MB 12.8 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 100.1/203.1 MB 12.8 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 100.7/203.1 MB 12.8 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 101.4/203.1 MB 12.9 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 101.9/203.1 MB 12.8 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 102.4/203.1 MB 12.6 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 102.9/203.1 MB 12.4 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 103.5/203.1 MB 12.4 MB/s eta 0:00:09\n",
      "   -------------------- ------------------ 104.2/203.1 MB 12.6 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 104.8/203.1 MB 12.6 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 105.5/203.1 MB 12.8 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 106.1/203.1 MB 13.1 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 106.8/203.1 MB 13.1 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 107.4/203.1 MB 13.1 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 107.9/203.1 MB 12.8 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 108.6/203.1 MB 13.1 MB/s eta 0:00:08\n",
      "   -------------------- ------------------ 109.2/203.1 MB 13.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 109.9/203.1 MB 13.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 110.5/203.1 MB 13.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 111.1/203.1 MB 13.1 MB/s eta 0:00:08\n",
      "   --------------------- ----------------- 111.7/203.1 MB 13.1 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 112.4/203.1 MB 13.4 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 113.0/203.1 MB 13.6 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 113.6/203.1 MB 13.6 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 114.2/203.1 MB 13.6 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 114.8/203.1 MB 13.4 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 115.5/203.1 MB 13.4 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 116.1/203.1 MB 13.4 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 116.8/203.1 MB 13.6 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 117.5/203.1 MB 13.6 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 118.1/203.1 MB 13.6 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 118.6/203.1 MB 13.4 MB/s eta 0:00:07\n",
      "   ---------------------- ---------------- 119.2/203.1 MB 13.4 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 120.0/203.1 MB 13.6 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 120.6/203.1 MB 13.6 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 121.3/203.1 MB 13.6 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 121.9/203.1 MB 13.6 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 122.7/203.1 MB 13.6 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 123.3/203.1 MB 13.9 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 124.1/203.1 MB 13.9 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 124.8/203.1 MB 14.2 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 125.6/203.1 MB 14.6 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 126.3/203.1 MB 14.5 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 127.0/203.1 MB 14.6 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 127.6/203.1 MB 14.6 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 128.3/203.1 MB 14.6 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 129.1/203.1 MB 14.9 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 129.8/203.1 MB 15.2 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 130.5/203.1 MB 14.9 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 131.2/203.1 MB 15.2 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 132.0/203.1 MB 15.2 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 132.8/203.1 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 133.5/203.1 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 134.2/203.1 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 135.0/203.1 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 135.6/203.1 MB 15.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 136.3/203.1 MB 15.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 137.0/203.1 MB 15.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 137.8/203.1 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 138.4/203.1 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 139.1/203.1 MB 15.6 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 139.8/203.1 MB 15.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 140.5/203.1 MB 15.2 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 141.2/203.1 MB 15.2 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 141.9/203.1 MB 14.9 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 142.6/203.1 MB 14.9 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 143.2/203.1 MB 14.9 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 143.9/203.1 MB 15.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 144.6/203.1 MB 14.9 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 145.3/203.1 MB 14.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 146.1/203.1 MB 15.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 146.9/203.1 MB 14.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 147.7/203.1 MB 15.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 148.3/203.1 MB 14.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 148.9/203.1 MB 15.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 149.5/203.1 MB 14.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 150.2/203.1 MB 14.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 150.9/203.1 MB 14.9 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 151.6/203.1 MB 14.6 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 152.4/203.1 MB 15.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 152.9/203.1 MB 14.9 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 153.5/203.1 MB 14.9 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 154.2/203.1 MB 14.9 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 154.9/203.1 MB 14.9 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 155.4/203.1 MB 14.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 156.1/203.1 MB 14.5 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 156.7/203.1 MB 14.2 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 157.4/203.1 MB 14.2 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 157.8/203.1 MB 13.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 157.8/203.1 MB 13.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 157.8/203.1 MB 13.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 157.8/203.1 MB 13.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 157.8/203.1 MB 13.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 157.8/203.1 MB 13.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 157.8/203.1 MB 13.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 160.7/203.1 MB 11.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 162.7/203.1 MB 13.1 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 163.3/203.1 MB 13.1 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 164.1/203.1 MB 13.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 164.8/203.1 MB 13.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 165.4/203.1 MB 13.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 166.0/203.1 MB 13.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 166.7/203.1 MB 13.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 167.5/203.1 MB 13.6 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 168.3/203.1 MB 24.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 168.8/203.1 MB 21.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 169.5/203.1 MB 19.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 170.1/203.1 MB 18.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 170.9/203.1 MB 16.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 171.6/203.1 MB 16.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 172.2/203.1 MB 14.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 173.0/203.1 MB 14.9 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 173.6/203.1 MB 14.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 174.3/203.1 MB 14.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 174.9/203.1 MB 14.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 175.7/203.1 MB 14.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 176.2/203.1 MB 14.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 176.8/203.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 177.4/203.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 178.0/203.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 178.6/203.1 MB 13.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.2/203.1 MB 13.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.9/203.1 MB 13.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 180.7/203.1 MB 13.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 181.5/203.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 182.1/203.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 182.8/203.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 183.5/203.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 184.1/203.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 184.9/203.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 185.4/203.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 186.0/203.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 186.6/203.1 MB 13.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 187.2/203.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 187.9/203.1 MB 14.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 188.4/203.1 MB 13.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 189.0/203.1 MB 13.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 189.6/203.1 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 190.3/203.1 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 190.9/203.1 MB 13.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 191.4/203.1 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 192.0/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 192.6/203.1 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 193.2/203.1 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 193.8/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 194.2/203.1 MB 12.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 194.8/203.1 MB 12.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 195.4/203.1 MB 12.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 195.9/203.1 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 196.6/203.1 MB 12.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 197.4/203.1 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.0/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.7/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.8/203.1 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  200.5/203.1 MB 12.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  201.1/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  201.7/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.2/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.9/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.1/203.1 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 203.1/203.1 MB 8.8 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.6/6.2 MB 13.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.2/6.2 MB 13.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.9/6.2 MB 13.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.6/6.2 MB 14.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.3/6.2 MB 13.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.0/6.2 MB 14.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.8/6.2 MB 14.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.6/6.2 MB 14.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.2/6.2 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 14.6 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, sympy, torch\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.11.1\n",
      "    Uninstalling sympy-1.11.1:\n",
      "      Successfully uninstalled sympy-1.11.1\n",
      "Successfully installed sympy-1.13.1 torch-2.5.1 typing-extensions-4.12.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in c:\\users\\hashi\\anaconda3\\lib\\site-packages (0.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf131f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, einsum\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e5aa18",
   "metadata": {},
   "source": [
    "## Building and Training Swin Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8ceec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicShift(nn.Module):\n",
    "    def __init__(self, displacement):\n",
    "        super().__init__()\n",
    "        self.displacement = displacement\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.roll(x, shifts=(self.displacement, self.displacement), dims=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eb1d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d65af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34f8465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc2b4b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(window_size, displacement, upper_lower, left_right):\n",
    "    mask = torch.zeros(window_size ** 2, window_size ** 2)\n",
    "\n",
    "    if upper_lower:\n",
    "        mask[-displacement * window_size:, :-displacement * window_size] = float('-inf')\n",
    "        mask[:-displacement * window_size, -displacement * window_size:] = float('-inf')\n",
    "\n",
    "    if left_right:\n",
    "        mask = rearrange(mask, '(h1 w1) (h2 w2) -> h1 w1 h2 w2', h1=window_size, h2=window_size)\n",
    "        mask[:, -displacement:, :, :-displacement] = float('-inf')\n",
    "        mask[:, :-displacement, :, -displacement:] = float('-inf')\n",
    "        mask = rearrange(mask, 'h1 w1 h2 w2 -> (h1 w1) (h2 w2)')\n",
    "\n",
    "    return mask\n",
    "\n",
    "def get_relative_distances(window_size):\n",
    "    indices = torch.tensor(np.array([[x, y] for x in range(window_size) for y in range(window_size)]))\n",
    "    distances = indices[None, :, :] - indices[:, None, :]\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "258b6e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowAttention(nn.Module):\n",
    "    def __init__(self, dim, heads, head_dim, shifted, window_size, relative_pos_embedding):\n",
    "        super().__init__()\n",
    "        inner_dim = head_dim * heads\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "        self.window_size = window_size\n",
    "        self.relative_pos_embedding = relative_pos_embedding\n",
    "        self.shifted = shifted\n",
    "\n",
    "        if self.shifted:\n",
    "            displacement = window_size // 2\n",
    "            self.cyclic_shift = CyclicShift(-displacement)\n",
    "            self.cyclic_back_shift = CyclicShift(displacement)\n",
    "            self.upper_lower_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\n",
    "                                                             upper_lower=True, left_right=False), requires_grad=False)\n",
    "            self.left_right_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\n",
    "                                                            upper_lower=False, left_right=True), requires_grad=False)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "\n",
    "        if self.relative_pos_embedding:\n",
    "            self.relative_indices = get_relative_distances(window_size) + window_size - 1\n",
    "            self.pos_embedding = nn.Parameter(torch.randn(2 * window_size - 1, 2 * window_size - 1))\n",
    "        else:\n",
    "            self.pos_embedding = nn.Parameter(torch.randn(window_size ** 2, window_size ** 2))\n",
    "\n",
    "        self.to_out = nn.Linear(inner_dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.shifted:\n",
    "            x = self.cyclic_shift(x)\n",
    "\n",
    "        b, n_h, n_w, _, h = *x.shape, self.heads\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
    "        nw_h = n_h // self.window_size\n",
    "        nw_w = n_w // self.window_size\n",
    "\n",
    "        q, k, v = map(\n",
    "            lambda t: rearrange(t, 'b (nw_h w_h) (nw_w w_w) (h d) -> b h (nw_h nw_w) (w_h w_w) d',\n",
    "                                h=h, w_h=self.window_size, w_w=self.window_size), qkv)\n",
    "\n",
    "        dots = einsum('b h w i d, b h w j d -> b h w i j', q, k) * self.scale\n",
    "\n",
    "        if self.relative_pos_embedding:\n",
    "            dots += self.pos_embedding[self.relative_indices[:, :, 0], self.relative_indices[:, :, 1]]\n",
    "        else:\n",
    "            dots += self.pos_embedding\n",
    "\n",
    "        if self.shifted:\n",
    "            dots[:, :, -nw_w:] += self.upper_lower_mask\n",
    "            dots[:, :, nw_w - 1::nw_w] += self.left_right_mask\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "\n",
    "        out = einsum('b h w i j, b h w j d -> b h w i d', attn, v)\n",
    "        out = rearrange(out, 'b h (nw_h nw_w) (w_h w_w) d -> b (nw_h w_h) (nw_w w_w) (h d)',\n",
    "                        h=h, w_h=self.window_size, w_w=self.window_size, nw_h=nw_h, nw_w=nw_w)\n",
    "        out = self.to_out(out)\n",
    "\n",
    "        if self.shifted:\n",
    "            out = self.cyclic_back_shift(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a2c86ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinBlock(nn.Module):\n",
    "    def __init__(self, dim, heads, head_dim, mlp_dim, shifted, window_size, relative_pos_embedding):\n",
    "        super().__init__()\n",
    "        self.attention_block = Residual(PreNorm(dim, WindowAttention(dim=dim,\n",
    "                                                                     heads=heads,\n",
    "                                                                     head_dim=head_dim,\n",
    "                                                                     shifted=shifted,\n",
    "                                                                     window_size=window_size,\n",
    "                                                                     relative_pos_embedding=relative_pos_embedding)))\n",
    "        self.mlp_block = Residual(PreNorm(dim, FeedForward(dim=dim, hidden_dim=mlp_dim)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.attention_block(x)\n",
    "        x = self.mlp_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8233f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMerging(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downscaling_factor):\n",
    "        super().__init__()\n",
    "        self.downscaling_factor = downscaling_factor\n",
    "        self.patch_merge = nn.Unfold(kernel_size=downscaling_factor, stride=downscaling_factor, padding=0)\n",
    "        self.linear = nn.Linear(in_channels * downscaling_factor ** 2, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        new_h, new_w = h // self.downscaling_factor, w // self.downscaling_factor\n",
    "        x = self.patch_merge(x).view(b, -1, new_h, new_w).permute(0, 2, 3, 1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "549ac280",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StageModule(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dimension, layers, downscaling_factor, num_heads, head_dim, window_size,\n",
    "                 relative_pos_embedding):\n",
    "        super().__init__()\n",
    "        assert layers % 2 == 0, 'Stage layers need to be divisible by 2 for regular and shifted block.'\n",
    "\n",
    "        self.patch_partition = PatchMerging(in_channels=in_channels, out_channels=hidden_dimension,\n",
    "                                            downscaling_factor=downscaling_factor)\n",
    "\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(layers // 2):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                SwinBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
    "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
    "                SwinBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
    "                          shifted=True, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_partition(x)\n",
    "        for regular_block, shifted_block in self.layers:\n",
    "            x = regular_block(x)\n",
    "            x = shifted_block(x)\n",
    "        return x.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55602681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformer(nn.Module):\n",
    "    def __init__(self, *, hidden_dim, layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
    "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stage1 = StageModule(in_channels=channels, hidden_dimension=hidden_dim, layers=layers[0],\n",
    "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
    "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
    "        self.stage2 = StageModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, layers=layers[1],\n",
    "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
    "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
    "        self.stage3 = StageModule(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, layers=layers[2],\n",
    "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
    "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
    "        self.stage4 = StageModule(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, layers=layers[3],\n",
    "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
    "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim * 8),\n",
    "            nn.Linear(hidden_dim * 8, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.stage1(img)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = x.mean(dim=[2, 3])\n",
    "        return self.mlp_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22234902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swin-T Model\n",
    "def swin_t(hidden_dim=96, layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
    "    return SwinTransformer(hidden_dim=hidden_dim, layers=layers, heads=heads, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71384ccb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# net = SwinTransformer(\n",
    "#     hidden_dim=96,\n",
    "#     layers=(2, 2, 6, 2),\n",
    "#     heads=(3, 6, 12, 24),\n",
    "#     channels=3,\n",
    "#     num_classes=3,\n",
    "#     head_dim=32,\n",
    "#     window_size=7,\n",
    "#     downscaling_factors=(4, 2, 2, 2),\n",
    "#     relative_pos_embedding=True\n",
    "# )\n",
    "# dummy_x = torch.randn(1, 3, 224, 224)\n",
    "# logits = net(dummy_x)  # (1,3)\n",
    "# # print(net)\n",
    "# print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614cd40b",
   "metadata": {},
   "source": [
    "## Building and Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fe252a7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/69/55/ce836703ff77bb21582c3098d5311f8ddde7eadc7eab04be9561961f4725/torchvision-0.20.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torchvision-0.20.1-cp311-cp311-win_amd64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: torch==2.5.1 in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from torchvision) (2.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (2023.4.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hashi\\anaconda3\\lib\\site-packages (from jinja2->torch==2.5.1->torchvision) (2.1.1)\n",
      "Downloading torchvision-0.20.1-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.6 MB 682.7 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.6 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.6 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.9/1.6 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.4/1.6 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 7.1 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f6f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191fd08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515852bc",
   "metadata": {},
   "source": [
    "**Using CIFAR10 dataset for now. Will need to change to ImageNet. Consider everything here as temporary. This may be moved to another section later** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c064b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 170M/170M [00:11<00:00, 15.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data\\cifar-10-python.tar.gz to ../data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root='../data', train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root='../data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80d34a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d13e05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 12, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(12, 24, 5)\n",
    "        self.fcl1 = nn.Linear(24 * 5 * 5, 120)\n",
    "        self.fcl2 = nn.Linear(120, 84)\n",
    "        self.fcl3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fcl1(x))\n",
    "        x = F.relu(self.fcl2(x))\n",
    "        x = self.fcl3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96fb5d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNeuralNet()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1844e445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0...\n",
      "Loss: 2.1864\n",
      "Training epoch 1...\n",
      "Loss: 1.7612\n",
      "Training epoch 2...\n",
      "Loss: 1.5316\n",
      "Training epoch 3...\n",
      "Loss: 1.4107\n",
      "Training epoch 4...\n",
      "Loss: 1.3164\n",
      "Training epoch 5...\n",
      "Loss: 1.2312\n",
      "Training epoch 6...\n",
      "Loss: 1.1502\n",
      "Training epoch 7...\n",
      "Loss: 1.0864\n",
      "Training epoch 8...\n",
      "Loss: 1.0313\n",
      "Training epoch 9...\n",
      "Loss: 0.9845\n",
      "Training epoch 10...\n",
      "Loss: 0.9421\n",
      "Training epoch 11...\n",
      "Loss: 0.9018\n",
      "Training epoch 12...\n",
      "Loss: 0.8684\n",
      "Training epoch 13...\n",
      "Loss: 0.8305\n",
      "Training epoch 14...\n",
      "Loss: 0.8000\n",
      "Training epoch 15...\n",
      "Loss: 0.7700\n",
      "Training epoch 16...\n",
      "Loss: 0.7431\n",
      "Training epoch 17...\n",
      "Loss: 0.7114\n",
      "Training epoch 18...\n",
      "Loss: 0.6868\n",
      "Training epoch 19...\n",
      "Loss: 0.6632\n",
      "Training epoch 20...\n",
      "Loss: 0.6403\n",
      "Training epoch 21...\n",
      "Loss: 0.6166\n",
      "Training epoch 22...\n",
      "Loss: 0.5902\n",
      "Training epoch 23...\n",
      "Loss: 0.5694\n",
      "Training epoch 24...\n",
      "Loss: 0.5448\n",
      "Training epoch 25...\n",
      "Loss: 0.5238\n",
      "Training epoch 26...\n",
      "Loss: 0.5038\n",
      "Training epoch 27...\n",
      "Loss: 0.4893\n",
      "Training epoch 28...\n",
      "Loss: 0.4662\n",
      "Training epoch 29...\n",
      "Loss: 0.4469\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    print(f'Training epoch {epoch}...')\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    print(f'Loss: {running_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e509388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'trained_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e42edd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hashi\\AppData\\Local\\Temp\\ipykernel_54160\\2378918482.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load('trained_net.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ConvNeuralNetralNetNload_state_dictet.load_state_dict(torch.load('trained_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b1ac609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 68.64%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * (correct / total)\n",
    "print(f\"Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0edc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
